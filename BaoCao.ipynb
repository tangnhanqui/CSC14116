{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training a Machine Learning model (Random Forest)"
      ],
      "metadata": {
        "id": "cmrVHOHqXuas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cài đặt thư viện cần thiết"
      ],
      "metadata": {
        "id": "EtD7Ft3DX7dH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "from numba import jit, prange\n",
        "from numba import config\n",
        "config.THREADING_LAYER = 'omp'"
      ],
      "metadata": {
        "id": "b3ykin0rCFxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tìm hiểu data\n",
        "## Input\n",
        "\n",
        "* Link Dataset http://archive.ics.uci.edu/ml/datasets/connectionist+bench+(sonar,+mines+vs.+rocks)\n",
        "* Tệp \"sonar.mines\" chứa 111 mẫu thu được bằng cách bật tín hiệu sonar ra khỏi một hình trụ kim loại ở nhiều góc độ khác nhau và trong các điều kiện khác nhau. \n",
        "* Tệp \"sonar.rocks\" chứa 97 mẫu thu được từ đá trong các điều kiện tương tự. Tín hiệu sonar truyền đi là một tiếng kêu được điều chỉnh tần số, tăng tần số. \n",
        "* Tập dữ liệu chứa các tín hiệu thu được từ nhiều góc độ khía cạnh khác nhau, trải dài 90 độ đối với hình trụ và 180 độ đối với đá.\n",
        "* Mỗi mẫu là một tập hợp gồm 60 số trong phạm vi từ 0,0 đến 1,0. Mỗi số đại diện cho năng lượng trong một dải tần số cụ thể, được tích hợp trong một khoảng thời gian nhất định. \n",
        "* Khẩu độ tích hợp cho các tần số cao hơn xảy ra muộn hơn trong thời gian, vì các tần số này được truyền sau đó trong tiếng kêu.\n",
        "* Nhãn liên kết với mỗi bản ghi chứa chữ cái \"R\" nếu đối tượng là một tảng đá và \"M\" nếu đó là mỏ (hình trụ kim loại).\n",
        "![](https://i.imgur.com/zaH8WGi.png)\n",
        "\n",
        "## Ouput\n",
        "* Là model sau khi được train\n",
        "\n",
        "##Source\n",
        "* Bộ dữ liệu được đóng góp vào việc thu thập điểm chuẩn bởi Terry Sejnowski, hiện đang làm việc tại Viện Salk và Đại học California tại San Deigo. \n",
        "* Bộ dữ liệu được phát triển với sự hợp tác của R. Paul Gorman của Trung tâm Công nghệ Hàng không Vũ trụ Allied-Signal.\n"
      ],
      "metadata": {
        "id": "pXS-ynZUSVXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sonar.all-data.csv')\n",
        "dataset = data.values\n",
        "data"
      ],
      "metadata": {
        "id": "Z5hBh2YJE2Qe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "66153c7c-ce83-46ea-f796-62983a438202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0.02  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
              "0    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
              "1    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
              "2    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
              "3    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
              "4    0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
              "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "202  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
              "203  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
              "204  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
              "205  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
              "206  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
              "\n",
              "     0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167   0.018  0.0084  \\\n",
              "0    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
              "1    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
              "2    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
              "3    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
              "4    0.3039  ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027   \n",
              "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "202  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
              "203  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
              "204  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
              "205  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
              "206  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
              "\n",
              "      0.009  0.0032  0  \n",
              "0    0.0052  0.0044  0  \n",
              "1    0.0095  0.0078  0  \n",
              "2    0.0040  0.0117  0  \n",
              "3    0.0107  0.0094  0  \n",
              "4    0.0051  0.0062  0  \n",
              "..      ...     ... ..  \n",
              "202  0.0193  0.0157  1  \n",
              "203  0.0062  0.0067  1  \n",
              "204  0.0077  0.0031  1  \n",
              "205  0.0036  0.0048  1  \n",
              "206  0.0061  0.0115  1  \n",
              "\n",
              "[207 rows x 61 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f356b315-7836-41ff-a6ce-8089ac87da83\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.02</th>\n",
              "      <th>0.0371</th>\n",
              "      <th>0.0428</th>\n",
              "      <th>0.0207</th>\n",
              "      <th>0.0954</th>\n",
              "      <th>0.0986</th>\n",
              "      <th>0.1539</th>\n",
              "      <th>0.1601</th>\n",
              "      <th>0.3109</th>\n",
              "      <th>0.2111</th>\n",
              "      <th>...</th>\n",
              "      <th>0.0027</th>\n",
              "      <th>0.0065</th>\n",
              "      <th>0.0159</th>\n",
              "      <th>0.0072</th>\n",
              "      <th>0.0167</th>\n",
              "      <th>0.018</th>\n",
              "      <th>0.0084</th>\n",
              "      <th>0.009</th>\n",
              "      <th>0.0032</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0286</td>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0277</td>\n",
              "      <td>0.0174</td>\n",
              "      <td>0.0384</td>\n",
              "      <td>0.0990</td>\n",
              "      <td>0.1201</td>\n",
              "      <td>0.1833</td>\n",
              "      <td>0.2105</td>\n",
              "      <td>0.3039</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.0038</td>\n",
              "      <td>0.0013</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0057</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>0.0187</td>\n",
              "      <td>0.0346</td>\n",
              "      <td>0.0168</td>\n",
              "      <td>0.0177</td>\n",
              "      <td>0.0393</td>\n",
              "      <td>0.1630</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.1694</td>\n",
              "      <td>0.2328</td>\n",
              "      <td>0.2684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0116</td>\n",
              "      <td>0.0098</td>\n",
              "      <td>0.0199</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0115</td>\n",
              "      <td>0.0193</td>\n",
              "      <td>0.0157</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>0.0323</td>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.0298</td>\n",
              "      <td>0.0564</td>\n",
              "      <td>0.0760</td>\n",
              "      <td>0.0958</td>\n",
              "      <td>0.0990</td>\n",
              "      <td>0.1018</td>\n",
              "      <td>0.1030</td>\n",
              "      <td>0.2154</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0093</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>0.0522</td>\n",
              "      <td>0.0437</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0292</td>\n",
              "      <td>0.0351</td>\n",
              "      <td>0.1171</td>\n",
              "      <td>0.1257</td>\n",
              "      <td>0.1178</td>\n",
              "      <td>0.1258</td>\n",
              "      <td>0.2529</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0160</td>\n",
              "      <td>0.0029</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0138</td>\n",
              "      <td>0.0077</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>0.0303</td>\n",
              "      <td>0.0353</td>\n",
              "      <td>0.0490</td>\n",
              "      <td>0.0608</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.1354</td>\n",
              "      <td>0.1465</td>\n",
              "      <td>0.1123</td>\n",
              "      <td>0.1945</td>\n",
              "      <td>0.2354</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0086</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0126</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>0.0079</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>0.0260</td>\n",
              "      <td>0.0363</td>\n",
              "      <td>0.0136</td>\n",
              "      <td>0.0272</td>\n",
              "      <td>0.0214</td>\n",
              "      <td>0.0338</td>\n",
              "      <td>0.0655</td>\n",
              "      <td>0.1400</td>\n",
              "      <td>0.1843</td>\n",
              "      <td>0.2354</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0146</td>\n",
              "      <td>0.0129</td>\n",
              "      <td>0.0047</td>\n",
              "      <td>0.0039</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0115</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>207 rows × 61 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f356b315-7836-41ff-a6ce-8089ac87da83')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f356b315-7836-41ff-a6ce-8089ac87da83 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f356b315-7836-41ff-a6ce-8089ac87da83');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Giới thiệu về Random Forest\n",
        "* Thuật toán Random Forest sẽ xây dựng nhiều cây quyết định bằng thuật toán Decision Tree\n",
        "* Tuy nhiên mỗi cây quyết định sẽ khác nhau (có yếu tố random). Sau đó kết quả dự đoán được tổng hợp từ các cây quyết định\n",
        "* Decision Tree là tên đại diện cho một nhóm thuật toán phát triển dựa trên Cây quyết định. Ở đó, mỗi Node của cây sẽ là các thuộc tính, và các nhánh là giá trị lựa chọn của thuộc tính đó. Bằng cách đi theo các giá trị thuộc tính trên cây,\n",
        "Cây quyết định sẽ cho ta biết giá trị dự đoán.\n"
      ],
      "metadata": {
        "id": "gUwbKsUoBAsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ưu điểm\n",
        "\n",
        "* Random Forest algorithm có thể sử dụng cho cả bài toán Classification và Regression\n",
        "* Khi Forest có nhiều cây hơn, chúng ta có thể tránh được việc Overfitting với tập dữ liệu"
      ],
      "metadata": {
        "id": "3Q4T8DSzCrZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Khuyết điểm\n",
        "* Random forests chậm tạo dự đoán bởi vì nó có nhiều cây quyết định. \n",
        "* Bất cứ khi nào nó đưa ra dự đoán, tất cả các cây trong rừng phải đưa ra dự đoán cho cùng một đầu vào cho trước và sau đó thực hiện bỏ phiếu trên đó. Toàn bộ quá trình này tốn thời gian. "
      ],
      "metadata": {
        "id": "vwV2wCRkPbaM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ứng dụng\n",
        "* Thuật toán Random Forest được sử dụng trong nhiều lĩnh vực khác nhau, chẳng hạn như ngân hàng, thị trường tài chính, y học, thương mại điện tử. \n",
        "*Ví dụ, trong lĩnh vực ngân hàng, nó được sử dụng để phát hiện những khách hàng sẽ sử dụng dịch vụ ngân hàng thường xuyên hơn những người khác và trả nợ đúng hạn. Trong lĩnh vực này, nó cũng được sử dụng để phát hiện hành vi gian lận của khách hàng muốn gây hại cho ngân hàng. \n",
        "* Trong lĩnh vực tài chính, nó được sử dụng để xác định hiệu suất trong tương lai của một cổ phiếu. \n",
        "* Trong chăm sóc sức khỏe, nó được sử dụng để xác định sự kết hợp chính xác của các thành phần trong y học và nó cũng được sử dụng để phân tích bệnh sử của bệnh nhân để xác định bệnh tật. \n",
        "* Trong thương mại điện tử, Random Forest được sử dụng để xác định xem khách hàng có thích sản phẩm hay không."
      ],
      "metadata": {
        "id": "x2NW4RvUQb1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cách hoạt động\n",
        "* Chọn các mẫu ngẫu nhiên từ tập dữ liệu đã cho.\n",
        "* Thiết lập cây quyết định cho từng mẫu và nhận kết quả dự đoán từ mỗi quyết định cây.\n",
        "* Hãy bỏ phiếu cho mỗi kết quả dự đoán.\n",
        "* Chọn kết quả được dự đoán nhiều nhất là dự đoán cuối cùng.\n",
        "![](https://i.imgur.com/O5TQ5K6.png)\n"
      ],
      "metadata": {
        "id": "R_uOU3DRC6UQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mã giả tạo ra nhiều cây \n",
        "* Chọn ngẫu nhiên “k” features từ tập “m” features. Chọn ngẫu nhiên số dòng dữ liệu từ dataset.\n",
        "Để ý k << m\n",
        "\n",
        "* Từ tập “k” features, tính toán ra node “d” là tốt nhất cho Node phân loại.\n",
        "\n",
        "* Chia các node con theo node tốt nhất vừa tìm được\n",
        "\n",
        "* Dùng thuật toán Decision Tree tạo cây cho Node tốt nhất.\n",
        "\n",
        "* Lặp lại bước 1-4 để tạo ra “n” cây"
      ],
      "metadata": {
        "id": "oGsrIDDPEx7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code tuần tự"
      ],
      "metadata": {
        "id": "Zhv0ox1tdouj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jit(parallel=True, cache=True)\n",
        "def gini(df):\n",
        "        x_unique,x_count = np.unique(df[:,-1], return_counts=True)\n",
        "        x_prob = x_count/np.sum(x_count)\n",
        "        x_gini = 1 - (np.dot(x_prob,x_prob))\n",
        "        return x_gini"
      ],
      "metadata": {
        "id": "HXbz_q-WRM1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## function picks the best value to split the real valued attribute \n",
        "def pick_the_value(df,n):\n",
        "        n_best = []\n",
        "        loss = 1000 # loss would not be more than 1 as gini is atmost 0.5\n",
        "        unique = np.sort(np.unique(df[:,n]))\n",
        "        split_values = [((unique[index]+unique[index-1])/2) for index in range(1,len(unique))]\n",
        "        if len(split_values) > 100 :\n",
        "            strip = list(range(1,100))\n",
        "            steps = np.ptp(df[:,n])/100\n",
        "            mini = np.min(df[:,n])\n",
        "            split_values = mini+(np.asarray(strip)*steps)\n",
        "\n",
        "        for i in split_values:\n",
        "            above = df[df[:,n] > i]\n",
        "            below = df[df[:,n] <= i] \n",
        "            a_gini = gini(above)\n",
        "            b_gini = gini(below)\n",
        "            a_len = len(above)\n",
        "            b_len = len(below)\n",
        "            current_loss = ((a_len/(a_len+b_len))*a_gini) + ((b_len/(a_len+b_len))*b_gini)\n",
        "            \n",
        "            if current_loss < loss:\n",
        "                loss = current_loss\n",
        "                n_best = [i,loss,above,below,n]\n",
        "        return n_best"
      ],
      "metadata": {
        "id": "Huadf2l7Rhjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## picks the best node(attribute) to split\n",
        "def decision_node(df):\n",
        "        node_split = []\n",
        "        par_loss = 1000\n",
        "        col_no = df.shape[1] - 1\n",
        "        par_list = np.random.choice(col_no,int(np.floor(np.sqrt(col_no))),replace=False)\n",
        "        for i in par_list:\n",
        "            i_best = pick_the_value(df,i)\n",
        "\n",
        "            if len(i_best)!=0 :\n",
        "                if i_best[1] < par_loss:\n",
        "                    par_loss = i_best[1]\n",
        "                    node_split = i_best\n",
        "        return node_split"
      ],
      "metadata": {
        "id": "q3WlOLxhRnM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## displaying the decision tree with tree pruning option (we can decide till which height the tree can go before stop, it decides the label based on the majority)\n",
        "def decisiontree(df):#,c = 0, m = 3):\n",
        "        x_unique = np.unique(df[:,-1])\n",
        "        if len(x_unique) == 1:# or c == m:\n",
        "            return x_unique[0]\n",
        "        else :\n",
        "            # c+=1\n",
        "            split = decision_node(df)\n",
        "            col_no = split[4]\n",
        "            value = split[0]\n",
        "            df_above = split[2]\n",
        "            df_below = split[3]\n",
        "            condition = \"{} <= {}\".format(col_no,value)\n",
        "            decision_tree = {condition : []}\n",
        "            true = decisiontree(df_below)#,c,m)\n",
        "            false = decisiontree(df_above)#,c,m)\n",
        "\n",
        "            decision_tree[condition].append(true)\n",
        "            decision_tree[condition].append(false)\n",
        "\n",
        "            return decision_tree"
      ],
      "metadata": {
        "id": "4vaWLSODRw1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## bootstrapping the datasets to generate multiple decision trees \n",
        "def bootstrap_decision_tree(df):\n",
        "        list_bootstrapped_tree = []\n",
        "        n = 15 ## number of bootstrapped datasets need to be created\n",
        "        for i in range(n):\n",
        "            index = np.random.choice(len(df),len(df),replace=True)\n",
        "            list_bootstrapped_tree.append(decisiontree(df[index]))\n",
        "        return list_bootstrapped_tree"
      ],
      "metadata": {
        "id": "ido29Jr2R8rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## test sample is being passed through the decision tree and label is assigned\n",
        "def classify(test_sample,tree):\n",
        "        condition = list(tree.keys())[0]\n",
        "        column_number = condition.split()[0]\n",
        "        value = condition.split()[2]\n",
        "        if test_sample[int(column_number)] <= float(value):\n",
        "            label = tree[condition][0]\n",
        "        else :\n",
        "            label = tree[condition][1]\n",
        "        if type(label) == dict:\n",
        "            sub_tree = label\n",
        "            return classify(test_sample,sub_tree)\n",
        "        else :\n",
        "            return label"
      ],
      "metadata": {
        "id": "T_iawMD4SG2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## label for a test sample is picked based on majority among the labels generated from bootstrapped decision trees for that test sample\n",
        "def predict(x_test,list_bootstrapped_tree):\n",
        "        y_pred = []#np.asarray([])\n",
        "        for test in x_test:\n",
        "            label_list = []\n",
        "            for i in list_bootstrapped_tree:\n",
        "                label_list.append(classify(test,i))\n",
        "            unique_labels,count = np.unique(label_list,return_counts=True)\n",
        "            y_pred.append(unique_labels[np.argmax(count)])\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "MWeby_5_SKTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jit(parallel=True, cache=True)\n",
        "def RandomForest(X_train,Y_train,X_test):   \n",
        "    Y_train = np.asarray([Y_train])\n",
        "    Y_train = np.swapaxes(Y_train,0,1)\n",
        "    df = np.append(X_train,Y_train,axis=1)\n",
        "    list_bootstrapped_tree = bootstrap_decision_tree(df)\n",
        "    y_pred = predict(X_test,list_bootstrapped_tree)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "6tIR81moSSwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jit(parallel=True, cache=True)\n",
        "def Accuracy(y_true,y_pred):\n",
        "    nppred = np.asarray(y_pred)\n",
        "    c = y_true - nppred\n",
        "    misclass = np.count_nonzero(c)\n",
        "    test_len = len(y_true)\n",
        "    accuracy = 1 - (misclass/test_len)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "js9vAtMQSX3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.random.seed(4563)\n",
        "data = pd.read_csv(\"/content/sonar.all-data.csv\", header = None , skiprows = 1)\n",
        "dataframe = pd.DataFrame()\n",
        "dataframe = pd.DataFrame(data)\n",
        "Y = dataframe.pop(dataframe.columns[-1])\n",
        "ind = np.random.choice(len(dataframe),len(dataframe)*8//10,replace=False)\n",
        "df = np.asarray(dataframe)\n",
        "label = np.asarray(Y)\n",
        "X_train = df[ind]\n",
        "X_test = np.delete(df,ind,axis = 0)\n",
        "Y_train = label[ind]\n",
        "Y_test = np.delete(label,ind,axis = 0)\n",
        "# train_len = len(x_train)\n",
        "# test_len = len(x_test)\n",
        "# col_len = x_train.shape[1]\n",
        "x_train_norm = (X_train - np.mean(X_train,axis = 0)[np.newaxis,:])/np.std(X_train,axis=0)[np.newaxis,:]\n",
        "x_test_norm = (X_test - np.mean(X_test,axis = 0)[np.newaxis,:])/np.std(X_test,axis=0)[np.newaxis,:]"
      ],
      "metadata": {
        "id": "YET18ag9ScMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rf = RandomForest(X_train,Y_train,X_test)\n",
        "print(\"Accuracy :\",Accuracy(Y_test,y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgVmbsRsSrhy",
        "outputId": "f208d969-acf4-41e0-8c78-866d6f8556f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.7380952380952381\n"
          ]
        }
      ]
    }
  ]
}